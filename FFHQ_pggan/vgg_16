import os
import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader

# ===========================================================
# æ•°æ®è·¯å¾„
# ===========================================================
train_dir = "/root/autodl-tmp/myrl/ffhq/small_sample/pggan_v2/train"
val_dir = "/root/autodl-tmp/myrl/ffhq/small_sample/pggan_v2/val"

# ===========================================================
# æ•°æ®å¢å¼ºï¼ˆæ¨¡ä»¿ TF ImageDataGeneratorï¼‰
# ===========================================================
transform_train = transforms.Compose([
    transforms.Resize((150, 150)),
    transforms.RandomRotation(30),
    transforms.RandomHorizontalFlip(),
    transforms.RandomAffine(0, translate=(0.2, 0.2), shear=10),
    transforms.RandomResizedCrop(150, scale=(0.8, 1.0)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

transform_val = transforms.Compose([
    transforms.Resize((150, 150)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

train_dataset = datasets.ImageFolder(train_dir, transform=transform_train)
val_dataset = datasets.ImageFolder(val_dir, transform=transform_val)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

print("ç±»åˆ«æ•°:", len(train_dataset.class_to_idx))
print("ç±»åˆ«æ˜ å°„:", train_dataset.class_to_idx)


# ===========================================================
# æ ‡å‡† VGG16ï¼ˆå¸¦ AdaptiveAvgPool2d(7Ã—7) â†’ ç‰¹å¾ç»´åº¦ ALWAYS 25088ï¼‰
# ===========================================================
class VGG16_Final(nn.Module):
    def __init__(self, num_classes):
        super().__init__()

        # åŠ è½½å®˜æ–¹é¢„è®­ç»ƒ VGG16
        self.base = models.vgg16_bn(weights="IMAGENET1K_V1")

        # å†»ç»“ç‰¹å¾å±‚ï¼ˆå¯é˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
        for param in self.base.features.parameters():
            param.requires_grad = False

        # VGG16 çš„ avgpool å›ºå®šè¾“å‡º 7Ã—7Ã—512 = 25088
        print("âš¡ ä½¿ç”¨æ ‡å‡† VGG16ï¼ŒFC è¾“å…¥ç»´åº¦å›ºå®šä¸º 25088")

        self.base.classifier = nn.Sequential(
            nn.Linear(25088, 4096),
            nn.ReLU(True),
            nn.Dropout(0.6),
            nn.Linear(4096, 256),
            nn.ReLU(True),
            nn.Dropout(0.6),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        return self.base(x)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
num_classes = len(train_dataset.class_to_idx)

model = VGG16_Final(num_classes).to(device)


# ===========================================================
# æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨
# ===========================================================
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=5e-5)

# å‡å°å­¦ä¹ ç‡çš„ç­–ç•¥
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=6, min_lr=1e-6, verbose=True
)

# EarlyStopping
best_val_loss = float("inf")
early_stop_counter = 0
EARLY_STOP_PATIENCE = 12

# ä¿å­˜å†å²
history = {"loss": [], "val_loss": [], "acc": [], "val_acc": []}


# ===========================================================
# è®­ç»ƒå‡½æ•°
# ===========================================================
def train_one_epoch():
    model.train()
    total_loss, correct = 0, 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)

        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * images.size(0)
        correct += (outputs.argmax(1) == labels).sum().item()

    return total_loss / len(train_dataset), correct / len(train_dataset)


# ===========================================================
# éªŒè¯å‡½æ•°
# ===========================================================
def validate():
    model.eval()
    total_loss, correct = 0, 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)

            loss = criterion(outputs, labels)
            total_loss += loss.item() * images.size(0)
            correct += (outputs.argmax(1) == labels).sum().item()

    return total_loss / len(val_dataset), correct / len(val_dataset)


# ===========================================================
# ä¸»è®­ç»ƒ
# ===========================================================
EPOCHS = 100
best_path = "/root/autodl-tmp/myrl/ffhq/result/best_vgg16.pth"
os.makedirs(os.path.dirname(best_path), exist_ok=True)

for epoch in range(EPOCHS):
    print(f"\n===== Epoch {epoch+1}/{EPOCHS} =====")

    train_loss, train_acc = train_one_epoch()
    val_loss, val_acc = validate()

    history["loss"].append(train_loss)
    history["acc"].append(train_acc)
    history["val_loss"].append(val_loss)
    history["val_acc"].append(val_acc)

    print(f"è®­ç»ƒ Loss: {train_loss:.4f}  Acc: {train_acc:.4f}")
    print(f"éªŒè¯ Loss: {val_loss:.4f}  Acc: {val_acc:.4f}")

    scheduler.step(val_loss)

    # EarlyStopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        early_stop_counter = 0
        torch.save(model.state_dict(), best_path)
        print("ğŸ”¥ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼")
    else:
        early_stop_counter += 1

    if early_stop_counter >= EARLY_STOP_PATIENCE:
        print("â›” è§¦å‘ Early Stopping")
        break

print("\nè®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯ Loss:", best_val_loss)


# ===========================================================
# å¯è§†åŒ–
# ===========================================================
plt.plot(history["acc"], label="Train Acc")
plt.plot(history["val_acc"], label="Val Acc")
plt.legend()
plt.title("Accuracy")
plt.show()

plt.plot(history["loss"], label="Train Loss")
plt.plot(history["val_loss"], label="Val Loss")
plt.legend()
plt.title("Loss")
plt.show()


# ===========================================================
# é¢„æµ‹éªŒè¯é›†
# ===========================================================
model.load_state_dict(torch.load(best_path))
model.eval()

all_preds = []
with torch.no_grad():
    for images, _ in val_loader:
        images = images.to(device)
        preds = model(images).argmax(1).cpu().numpy()
        all_preds.extend(preds)

all_preds = np.array(all_preds)


# ===========================================================
# æ˜¾ç¤ºé¢„æµ‹æ ·æœ¬ï¼ˆæ¨¡ä»¿ TFï¼‰
# ===========================================================
inv_norm = transforms.Normalize(
    mean=[-1, -1, -1], std=[2, 2, 2]
)

def show(img, true, pred):
    img = inv_norm(img).permute(1, 2, 0).numpy()
    classes = list(train_dataset.class_to_idx.keys())
    plt.imshow(img)
    plt.title(f"True: {classes[true]}\nPred: {classes[pred]}")
    plt.axis("off")
    plt.show()


val_iter = iter(val_loader)
images, labels = next(val_iter)

for i in range(10):
    show(images[i], labels[i].item(), all_preds[i])

